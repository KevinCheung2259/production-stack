servingEngineSpec:
  runtimeClassName: ""
  modelSpec:
  - name: "captain"
    repository: "vllm/vllm-openai"
    tag: "latest"
    modelURL: "Nitral-AI/Captain-Eris_Violet-V0.420-12B"
    replicaCount: 2

    requestCPU: 10
    requestMemory: "16Gi"
    requestGPU: 1

    pvcStorage: "30Gi"
    pvcAccessMode:
      - ReadWriteOnce
    pvcMatchLabels:
      model: "captain-pv"

    vllmConfig:
      maxModelLen: 10000
      enableChunkedPrefill: true
      enablePrefixCaching: true
      dtype: "auto"
      extraArgs: ["--disable-log-requests", 
                  "--gpu-memory-utilization", "0.9", 
                  "--served-model-name", "Nitral-AI/Captain-Eris_Violet-V0.420-12B",
                  "--swap-space", "4",
                  "--max-num-seqs", "72", 
                  "--max-num-batched-tokens", "1024",
                  "--quantization", "fp8",
                  "--kv-cache-dtype", "fp8",
                  ]

routerSpec:
  repository: "lmcache/lmstack-router"
  tag: "latest"
  # repository: "vllm-router"
  # tag: "2025-04-25"
  imagePullPolicy: "IfNotPresent"
  resources:
    requests:
      cpu: "2"
      memory: "8G"
    limits:
      cpu: "2"
      memory: "8G"
  routingLogic: "session"  # roundrobin, session
  sessionKey: "X-Flow-Conversation-Id"